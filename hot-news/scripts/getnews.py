import requests
from lxml import etree
import re
import json
from bs4 import BeautifulSoup

"""
ä¸ºä¾¿äºå­¦ä¹ ï¼Œæ—§ä»£ç ä»…æ³¨é‡Šï¼Œæœªåˆ é™¤
"""

class HotNews(object):
    headers = {
            "User-Agent":"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36",
        }
    

    def __init__(self, n):
        """
        param: n: éœ€è¦è·å–çš„çƒ­æœæ•°é‡ 
        """
        self.n = n

    def getweiboNews(self):
        """
        å¾®åšçƒ­æ¦œ
        """
        cookies = {
        'SUB': '_2AkMTtDIMf8NxqwFRmP8RzWLkbY10zwrEieKl6MPXJRMxHRl-yT9vqhMDtRB6ODQc4yM_gWCs-qcHIFpIc0srV4-ZzbJK'
        }
        url = 'https://s.weibo.com/top/summary'

        res = requests.get(url=url, headers=self.headers, cookies=cookies, verify=False)
        tree = etree.HTML(res.content)
        
        wb_hot_news = dict()
        
        for i in range(self.n + 5):
            counter = len(wb_hot_news)
            link_suffix = tree.xpath(f'//*[@id="pl_top_realtimehot"]/table/tbody/tr[{i}]/td[2]/a/@href')
            title = tree.xpath(f'//*[@id="pl_top_realtimehot"]/table/tbody/tr[{i}]/td[2]/a/text()')
            count_str = tree.xpath(f'//*[@id="pl_top_realtimehot"]/table/tbody/tr[{i}]/td[2]/span/text()')

            if link_suffix and title and count_str:
                link = 'https://s.weibo.com' + str(link_suffix[0])
                hot_count = re.sub(r'[\D]', '', count_str[0])
                if hot_count:
                    try:
                        title_hot = str(title[0])
                    except:
                        title_hot = 0
                    if counter < self.n:
                        wb_hot_news[title_hot] = {'hot': 'ğŸ”¥' + str(hot_count), 'link': link}

        return wb_hot_news
    
    
    def getZhihuNews(self):
        """
        çŸ¥ä¹çƒ­æ¦œ
        """
        url = 'https://www.zhihu.com/billboard'
        res = requests.get(url=url, headers=self.headers, verify=False)
        tree = etree.HTML(res.content)

        zh_news = dict()

        _ = tree.xpath('//*[@id="js-initialData"]/text()')
        json_data = _[0].encode('utf-8')
        dict_data = dict(json.loads(json_data))
        list_data = dict_data['initialState']['topstory']['hotList']
        for data in list_data:
            counter = len(zh_news)
            title = data['target']['titleArea']['text']
            desc = data['target']['excerptArea']['text']
            link = data['target']['link']['url']
            hot_count = data['target']['metricsArea']['text'].replace('çƒ­åº¦', '')

            if desc:
                describes = ' ğŸ“œ' + desc
            else:
                describes = ''

            if counter < self.n:
                zh_news[title] = {'hot': 'ğŸ”¥' + hot_count + describes, 'link': link}
                continue
            
        return zh_news
    
    def getTiebaNews(self):
        """
        ç™¾åº¦è´´å§çƒ­æ¦œ
        """
        cookies = {
                "BAIDUID": "402F999DB23145A3CEFDE2358591947C:FG=1",
            }
        params={
                "res_type": "1",
            }
        url = 'https://c.tieba.baidu.com/hottopic/browse/topicList'

        res = requests.get(url=url, headers=self.headers, cookies=cookies, params=params, verify=False)
        html = res.text

        soup = BeautifulSoup(html, 'html.parser')

        tb_hot_news = dict()

        for i in range(self.n + 5):
            counter = len(tb_hot_news)
            text_infos = soup.select(f"body > div.wrap1 > div > div.bang-bg > div > div.topic-body.clearfix > div.main > ul > li:nth-child({i}) > div > div > a")
            desc_infos = soup.select(f"body > div.wrap1 > div > div.bang-bg > div > div.topic-body.clearfix > div.main > ul > li:nth-child({i}) > div > p")
            count_strs = soup.select(f"body > div.wrap1 > div > div.bang-bg > div > div.topic-body.clearfix > div.main > ul > li:nth-child({i}) > div > div > span.topic-num")

            if text_infos and count_strs:
                for text_info in text_infos:
                    link = text_info.get('href')
                    title = text_info.text
                        
                for count_str in count_strs:
                    counter_str = count_str.text.replace('å®æ—¶è®¨è®º','')

                for desc in desc_infos:
                    desc_str = desc.text
                
                if desc_str:
                    describes = ' ğŸ“œ' + desc_str
                else:
                    describes = ''

                if counter < self.n:
                    tb_hot_news[title] = {'hot': 'ğŸ”¥' + counter_str + describes, 'link': link}
        
        return tb_hot_news
    
    def getZHribaoNews(self):
        """
        çŸ¥ä¹æ—¥æŠ¥
        """
        url = 'https://daily.zhihu.com/'
        res = requests.get(url=url, verify=False)
        tree = etree.HTML(res.content.decode())

        rb_hot_news = dict()

        for i in range(self.n + 5):
            counter  = len(rb_hot_news)
            title = tree.xpath(f'/html/body/div[3]/div/div[2]/div/div[1]/div[{i}]/div/a/span/text()')
            link_suffix = tree.xpath(f'/html/body/div[3]/div/div[2]/div/div[1]/div[{i}]/div/a/@href')
            if title and link_suffix:
                title = str(title[0])
                link = 'https://daily.zhihu.com' + str(link_suffix[0])
                if counter < self.n:
                    rb_hot_news[title] = {'hot': '', 'link': link}
        
        return rb_hot_news
        
    def getV2exNews(self, tab='hot'):
        """
        v2exçƒ­é—¨å¸–å­
        """
        url = 'https://www.v2ex.com/'
        params={
                "tab": tab, # "hot",
            }
        res = requests.get(url=url, params=params, verify=False)
        html = etree.HTML(res.text)

        temp_v2ex = dict()

        html_result = html.xpath('//*[contains(@class, "cell item")]')
        for result in html_result:
            # æ ‡é¢˜ç­‰æ•°æ®åœ¨spanåçš„classä¸‹
            title_elements = result.xpath('.//span[contains(@class, "item_title")]/a/text()')
            title = title_elements[0]

            # é“¾æ¥åç¼€åœ¨hrefä¸‹
            _link_suffix = result.xpath('.//span[contains(@class, "item_title")]/a/@href')
            link_suffix = _link_suffix[0]
            link = 'https://www.v2ex.com' + link_suffix

            node_elements = result.xpath('.//span[contains(@class, "topic_info")]/a/text()')
            node = node_elements[0]

            # å›å¤æ•°æ®æ˜¯åœ¨aåçš„classä¸‹
            hot_elements = result.xpath('.//a[contains(@class, "count_livid")]/text()')
            try:
                hot_count = int(hot_elements[0])
            except:
                hot_count = 0


            temp_v2ex[title] = {'hot': 'ğŸŒ³' + node + ' ğŸ’¬' + str(hot_count), 'link': link}


        # æå–idåŒ…å«topic-linkçš„æ‰€æœ‰å†…å®¹ï¼Œè¿”å›åˆ—è¡¨
        # html_result = html.xpath('//*[contains(@id, "topic-link")]')
        # for result in html_result:
        #     # åˆ—è¡¨ä¸­æ¯ä¸ªå…ƒç´ è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        #     result_new = etree.tostring(result, encoding='utf-8').decode()
        #     # HTMLè§£æ
        #     soup = BeautifulSoup(result_new, 'html.parser')
            
        #     # è·å–aå…ƒç´ 
        #     a_tag = soup.find('a')
            
        #     # è·å–é“¾æ¥ä¿¡æ¯
        #     href_value = a_tag['href']
        #     # æ‹¼æ¥å®Œæ•´é“¾æ¥
        #     link = 'https://www.v2ex.com' + href_value
        #     # è·å–æ ‡é¢˜æ–‡æœ¬
        #     text_content = a_tag.text
        #     # å–å‡ºé“¾æ¥ä¸­å›å¤æƒ…å†µæ‹¼æ¥åˆ°æ ‡é¢˜
        #     title = text_content
        #     reply_count = href_value.split('#')[-1].replace('reply', '')
            
        #     temp_v2ex[title] = {'hot': 'ğŸ’¬' + reply_count, 'link': link}
            
        v2ex_hot_news = dict()
        total = len(temp_v2ex)
        if self.n > total:
            counter = total
        else:
            counter = self.n
        
        v2ex_hot_news = {k: temp_v2ex[k] for k in list(temp_v2ex.keys())[:counter]}
        return v2ex_hot_news
    
    def getAppinnNews(self):
        """
        å°ä¼—è½¯ä»¶å¸–å­
        """
        url = 'https://meta.appinn.net'
        res = requests.get(url=url, verify=False)
        html = etree.HTML(res.text)

        temp_appinn = dict()

        html_result = html.xpath('//*[contains(@class, "topic-list-item")]')
        for result in html_result:
            title_elements = result.xpath('.//span[contains(@class, "link-top-line")]/a/text()')
            title = title_elements[0]

            _link_suffix = result.xpath('.//span[contains(@class, "link-top-line")]/a/@href')
            link_suffix = _link_suffix[0]
            link = url + link_suffix

            temp_appinn[title] = {'hot': '', 'link': link}


        # # è½¬ä¸ºstringï¼Œä¾¿äºBeautifulSoupå¤„ç†
        # string_html = etree.tostring(html, encoding='utf-8').decode()
        
        # soup = BeautifulSoup(string_html, 'html.parser')
        # a_tags = soup.find_all('a')

        # temp_appinn = dict()
        # for a_tag in a_tags:
        #     # ç½‘é¡µé“¾æ¥
        #     href_value = a_tag['href']
        #     if re.search(r'topic/\d+', href_value):
        #         title = a_tag.text
        #         if title != 'æ¬¢è¿æ¥åˆ°å°ä¼—è½¯ä»¶è®ºå›':
        #             temp_appinn[title] = {'hot': '', 'link': href_value}
        
        total = len(temp_appinn)
        appinn_hot_news = dict()
        if self.n > total:
            counter = total
        else:
            counter = self.n
        
        appinn_hot_news = {k: temp_appinn[k] for k in list(temp_appinn.keys())[:counter]}
        return appinn_hot_news
    

    def getBilibiliHots(self):
        """
        bilibili
        """
        url = 'https://api.bilibili.com/x/web-interface/popular'
        params = {
            "ps": self.n
        }

        res = requests.get(url=url, headers=self.headers, params=params, verify=False).json()
        list_data = res['data']['list']

        bilibiliHots = {}

        for data in list_data:
            title = data['title']
            name = data['owner']['name']
            view = data['stat']['view'] if data['stat']['view'] else 0
            desc = data['dynamic']
            link = data['short_link_v2']

            if desc:
                describes = ' ğŸ“œ' + desc
            else:
                describes = ''

            bilibiliHots[title] = {'hot': 'ğŸ‘€' + str(view) + ' ğŸ‘¤' + name + describes, 'link': link}
        
        return bilibiliHots



def main():
    hotnews = HotNews(2)

    getBilibiliHots = hotnews.getBilibiliHots()
    print(getBilibiliHots)
    pass
    

if __name__ == "__main__":
    main()
